{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c5c54c-342b-484b-9ce0-e1263132517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import xlora\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0225750b-c9aa-4eaf-a1bd-f428948cf752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aritrad/moe-directory/moe-datasets/TDIUC/custom-moe/using-sbert'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437a5205-ae83-4f84-8759-b4d9c5943995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import AdamW\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, AutoConfig, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9ad283-f10c-4f7b-8fbc-8af07ef37d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Conda environment: stable_env\n"
     ]
    }
   ],
   "source": [
    "conda_env = os.environ.get(\"CONDA_DEFAULT_ENV\")\n",
    "print(f\"Current Conda environment: {conda_env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a714746-2df4-45c6-b1f4-4fd4b5349670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c1fb12c-63b7-42b4-80e9-afe8e3ac49f2",
   "metadata": {},
   "source": [
    "### Load the Prototype Mixed Precision Dataset (For Router Training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ceb201-401e-4506-b875-37ccf3b6f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling (Serialization)\n",
    "\n",
    "with open('/home/aritrad/moe-directory/moe-datasets/TDIUC/prototype-train-set-8k-for-router-machine-automatic-llama3.2-annotation.pickle', 'rb') as file:\n",
    "    mixed_reasoning_data_prototype = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e6dfaf2-1bf9-4746-afe0-94dde6078f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'image_id': 'COCO_val2014_000000500316.jpg',\n",
       "   'question': 'What color ski gear does the person have?',\n",
       "   'question_id': 20011883,\n",
       "   'serial_no': 1509,\n",
       "   'reasoning_type': 'Physical Reasoning.',\n",
       "   'answer': 'blue'},\n",
       "  {'image_id': 'COCO_val2014_000000308645.jpg',\n",
       "   'question': 'How many people are in the room?',\n",
       "   'question_id': 30270039,\n",
       "   'serial_no': 2494,\n",
       "   'reasoning_type': 'Quantity Reasoning.',\n",
       "   'answer': 'one'}],\n",
       " 8000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_reasoning_data_prototype[0:2], len(mixed_reasoning_data_prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72965e57-7b04-4782-9174-455ac5249e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Physical Reasoning.': 2000,\n",
       "         'Quantity Reasoning.': 2000,\n",
       "         'Spatial Reasoning.': 2000,\n",
       "         'Social and Emotional Reasoning.': 2000})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count reasoning types\n",
    "reasoning_counts = Counter(item[\"reasoning_type\"] for item in mixed_reasoning_data_prototype)\n",
    "reasoning_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81034ff6-6673-4e65-964a-54591ff07d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# subsetting for testing\\n\\nmixed_reasoning_data_prototype_xlora = mixed_reasoning_data_prototype_xlora[:500]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# subsetting for testing\n",
    "\n",
    "mixed_reasoning_data_prototype_xlora = mixed_reasoning_data_prototype_xlora[:500]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9749d10b-b289-43ed-a639-4e03e5a2b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of mixed reasoing dataset: 8000\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of mixed reasoing dataset: {len(mixed_reasoning_data_prototype)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab699eb0-e9b8-47ac-bfbb-b92bb8a2b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d888c0c2-67ce-4397-9b8a-5933061c8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = \"/home/aritrad/moe-directory/moe-datasets/TDIUC/TDIUC/Images/val2014\"\n",
    "prefix = \"Generate a one word answer for the given image and question: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce613199-5514-48c2-9194-7d993f2b24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_names = [\"Physical Reasoning.\", \"Quantity Reasoning.\", \"Spatial Reasoning.\", \"Social and Emotional Reasoning.\"]\n",
    "label2id = {name: idx for idx, name in enumerate(expert_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fab794c-be99-4fe4-9ece-09cc53d82ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension to update reasoning_type\n",
    "mixed_reasoning_data_prototype = [\n",
    "    {**item, 'reasoning_type': label2id[item['reasoning_type']]}\n",
    "    for item in mixed_reasoning_data_prototype\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70361ac2-d101-4d49-8597-d72194f3abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "listToDictionary = {\n",
    "    'question': [ prefix + dict_['question'] for dict_ in mixed_reasoning_data_prototype ], \n",
    "    'image': [ os.path.join(image_folder_path, dict_['image_id']) for dict_ in mixed_reasoning_data_prototype ],\n",
    "    'reasoning_type': [ dict_['reasoning_type'] for dict_ in mixed_reasoning_data_prototype ]\n",
    "}\n",
    "\n",
    "reasonining_type_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3558b9d-dea0-4a61-ae38-d214e2845c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reasonining_type_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c53afd9-b3dc-412f-9086-97eddcc196af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train and Test\n",
    "\n",
    "split = reasonining_type_set.train_test_split(test_size=1000, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a3876dd-2944-443e-9543-4b84257cff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = split['train']\n",
    "val_set = split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7af00f34-6e6e-44c6-b4c2-18e9c47122c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12151aba-94e2-42db-8366-b6f44e997c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22024e7c-929b-4136-b10f-467b88245925",
   "metadata": {},
   "source": [
    "### Load Main Test Set (For Measuring Router Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8bbad2d-50ce-49d2-8f52-5dccaf3b9397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling (Serialization)\n",
    "\n",
    "with open('/home/aritrad/moe-directory/moe-datasets/TDIUC/prototype-test-set-2k-machine-automatic-llama3.2-annotation.pickle', 'rb') as file:\n",
    "    test_set = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "750624de-8a88-47f3-8006-bb7b07f8850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension to update reasoning_type\n",
    "\n",
    "test_set = [\n",
    "    {**item, 'reasoning_type': label2id[item['reasoning_type']]}\n",
    "    for item in test_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e23dadee-4426-48b7-b7c4-1451d54c9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "listToDictionary = {\n",
    "    'question': [ prefix + dict_['question'] for dict_ in test_set ], \n",
    "    'image': [ os.path.join(image_folder_path, dict_['image_id']) for dict_ in test_set ],\n",
    "    'reasoning_type': [ dict_['reasoning_type'] for dict_ in test_set ]\n",
    "}\n",
    "\n",
    "test_set = Dataset.from_dict(listToDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d36fc3df-5ae1-4d29-ab03-d1c02c46215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'question': 'Generate a one word answer for the given image and question: How many stop signs can be seen?',\n",
       "  'image': '/home/aritrad/moe-directory/moe-datasets/TDIUC/TDIUC/Images/val2014/COCO_val2014_000000252332.jpg',\n",
       "  'reasoning_type': 1},\n",
       " 2000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0], len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea620364-e496-44b0-9d44-f56736f591f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3aceb55-6599-40be-b3f7-e8c3164c6df0",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e24d5-a7ef-4769-bbe8-e9b99207334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3763f30-b3fc-47bd-bd5d-6a3a9707032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3532954-624a-4d98-9db0-a529afb1e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer   = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "sbert_model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78125d0-df44-4eac-ac96-4dff8d465941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "466d7ba8-4068-4ab7-9643-516387401089",
   "metadata": {},
   "source": [
    "### Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f6884-3b4e-4b01-aecb-c5f0d8aa2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    # pull out the raw strings and integer labels\n",
    "    questions = [ex[\"question\"] for ex in examples]\n",
    "    labels    = torch.tensor([ex[\"reasoning_type\"] for ex in examples],\n",
    "                             dtype=torch.long)\n",
    "    return {\n",
    "        'questions': questions, \n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955642e1-0dcb-4bd3-94c8-f4b5e1882785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = True,\n",
    "                          collate_fn = collate_fn)\n",
    "\n",
    "val_loader = DataLoader(val_set,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = True,\n",
    "                          collate_fn = collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_set,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = False,\n",
    "                          collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d21433-58ba-43ae-8fac-ce27877b37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the batch.\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde2baf-78e9-45d2-99d0-1873d0bae4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of batches in the Training Set: {len(train_loader)}, Test Set: {len(test_loader)} and Val Set: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca44e78-1334-4b23-8c40-e6cebde5812f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64f9ec28-27c8-478d-8a91-2c87692723dd",
   "metadata": {},
   "source": [
    "### Router Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16abe6-b976-4c92-a8f6-f8e9e2a00134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden=768, n_experts=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden // 2, hidden // 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden // 4, n_experts)\n",
    "        )\n",
    "        \n",
    "    def forward(self, fused):          # (B, 1536)\n",
    "        return self.net(fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13bbe5f-95de-4f78-afe7-e86e64a8480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for testing saved router checkpoint on other test sets.\n",
    "# Comment this block when Traininig.\n",
    "\n",
    "router = Router(n_experts=len(expert_names)).to(device)\n",
    "print(\"Router Initialized ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734d82e-f71f-4b3b-b097-33be53fb6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_count = sum(p.numel() for p in router.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {param_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2274a357-743f-4c02-b687-3a24a822f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(last_hidden_state, attention_mask):\n",
    "    mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "    summed         = torch.sum(last_hidden_state * mask_expanded, dim=1)\n",
    "    counts         = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)\n",
    "    return summed / counts  # (B, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192ac48-a0f0-47e5-90b4-de5f6057d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List parameters of both the router and the sbert\n",
    "\n",
    "optimizer = AdamW(\n",
    "    list(sbert_model.parameters()) + list(router.parameters()),\n",
    "    lr = 5e-6\n",
    ")\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55920073-97be-4085-b064-9a33a53bedfc",
   "metadata": {},
   "source": [
    "### Train and Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4bd91c-52c1-49fa-bf97-1e16ad845836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    \n",
    "    sbert_model.eval()\n",
    "    router.eval()\n",
    "    correct = total = 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for batch in tqdm(loader):\n",
    "            questions, labels = batch[\"questions\"], batch[\"labels\"].to(device)\n",
    "            \n",
    "            # tokenize & embed\n",
    "            enc = tokenizer(\n",
    "                questions,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            \n",
    "            out    = sbert_model(**enc)\n",
    "            embeds = mean_pooling(out.last_hidden_state, enc[\"attention_mask\"])\n",
    "            \n",
    "            # router forward\n",
    "            preds = router(embeds).argmax(dim=-1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56719b56-054a-4e70-97dd-a57216c94e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[•] Training router …\")\n",
    "best = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac6518-3227-4e5b-8693-b07470f901b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    sbert_model.train()\n",
    "    router.train()\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        questions, labels = batch[\"questions\"], batch[\"labels\"].to(device)\n",
    "\n",
    "        # inline get_text_repr\n",
    "        enc = tokenizer(\n",
    "            questions,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        out    = sbert_model(**enc)\n",
    "        embeds = mean_pooling(out.last_hidden_state, enc[\"attention_mask\"])\n",
    "\n",
    "        # forward + loss (float32)\n",
    "        logits = router(embeds)\n",
    "        loss   = loss_func(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % 40 == 0:\n",
    "            print(f\"Epoch {epoch+1} Step {step:4d} → loss {loss.item():.4f}\")\n",
    "\n",
    "    val_acc = evaluate(val_loader)\n",
    "    print(f\"\\n|| Epoch {epoch+1} → val acc = {val_acc:.3%} ||\\n\")\n",
    "\n",
    "    if val_acc > best:\n",
    "        best = val_acc\n",
    "        torch.save({\n",
    "            \"sbert_model\": sbert_model.state_dict(),\n",
    "            \"router\":      router.state_dict(),\n",
    "            \"optimizer\":   optimizer.state_dict()\n",
    "        }, \"best_joint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2a65b-bc2e-49e7-9949-bcf9826d22b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3a6ce-686a-49d9-9071-aa320d3ba169",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate(test_loader)\n",
    "print(f'Test Set accuracy of the Router is: {test_acc*100:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b293f2-3502-487b-ada6-5e8cdecbf79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592be88a-4f77-4328-8393-47edafef9095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f2696e-4336-4637-a719-ae6c7159e0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86147c09-18c2-41cb-b828-ca385c8f8bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a63af1-9060-4bf7-a4cb-1fed663388b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
